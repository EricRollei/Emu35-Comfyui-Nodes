# ComfyUI Emu 3.5 Nodes

This custom node allows you to run the Emu 3.5 model (Text-to-Image) in ComfyUI.

## Installation

1.  **Clone the Emu 3.5 Repository:**
    You must clone the official Emu 3.5 repository into a folder named `Emu3_5_repo` inside this node's directory.
    ```bash
    cd ComfyUI/custom_nodes/emu35
    git clone https://github.com/baaivision/Emu3.5 Emu3_5_repo
    ```

2.  **Install Requirements:**
    ```bash
    pip install -r requirements.txt
    ```
    Note: You might need to install `flash-attn` separately depending on your system.

3.  **Download Weights:**
    Download the Emu 3.5 weights from Hugging Face: [BAAI/Emu3.5-Image](https://huggingface.co/BAAI/Emu3.5-Image)
    Place them in `ComfyUI/models/emu35`.
    You also need the Vision Tokenizer (VQ-VAE) weights. If they are separate, place them in `ComfyUI/models/emu35/vision_tokenizer` or similar.

## Usage

1.  **Emu 3.5 Loader:**
    - Select the model checkpoint.
    - Choose precision (bf16 is recommended).
    - Choose `nf4` for 4-bit quantization (requires `bitsandbytes`).

2.  **Emu 3.5 Sampler:**
    - Connect the model, tokenizer, and VQ model from the loader.
    - Enter your prompt.
    - Adjust width, height, steps, and CFG.

## Quantization

To create a 4-bit quantized model (nF4) for faster loading and lower VRAM usage:

1.  Run the `quantize.py` script:
    ```bash
    python quantize.py --model_path path/to/original/model --output_path path/to/save/quantized/model
    ```
2.  Then load the quantized model using the Loader node with `precision="nf4"`.
